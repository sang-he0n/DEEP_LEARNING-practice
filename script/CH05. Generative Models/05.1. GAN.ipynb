{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH05.1. **Generative Adversarial Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. **작업 환경 설정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 00.0. **사전 변수 설정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_NUM = 2025\n",
    "BATCH_SIZE = 2\n",
    "EPOCH_NUM = 100\n",
    "USE_CHECKPOINT_YN = 'N'\n",
    "MODEL_PTH = '../../model/mnistFashionGAN.pt'\n",
    "LOGGER_PTH = '../../log/mnistFashionTrainLogger.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 00.1. **라이브러리 호출 및 옵션 설정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Device : mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc40648d15f847afa82dac649e2e336c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#(1) Import libraries\n",
    "import os\n",
    "import ipywidgets\n",
    "import random\n",
    "import tqdm\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torchvision\n",
    "import torchinfo\n",
    "\n",
    "#(2) Set up options\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED_NUM)\n",
    "random.seed(a=SEED_NUM)\n",
    "np.random.seed(seed=SEED_NUM)\n",
    "torch.use_deterministic_algorithms(mode=True)\n",
    "torch.manual_seed(seed=SEED_NUM)\n",
    "torch.mps.manual_seed(seed=SEED_NUM)\n",
    "\n",
    "#(3) Set up device\n",
    "if torch.backends.mps.is_available() :\n",
    "    device = torch.device(device='mps')\n",
    "else :\n",
    "    device = torch.device(device='cpu')\n",
    "print(f'>> Device : {device}')\n",
    "\n",
    "#(4) Set up HTML tag\n",
    "display(ipywidgets.HTML(data=\n",
    "'''\n",
    "<style> \n",
    "    .white-play button {\n",
    "        background-color: white !important; \n",
    "        color: black !important;\n",
    "    } \n",
    "</style>\n",
    "'''\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 00.2. **사용자정의함수 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Define `show_img` function\n",
    "def show_img(df:torchvision.datasets, index:int) -> plt.figure :\n",
    "    img = df[index][0]\n",
    "    target = df[index][1]\n",
    "    img = (img/2+0.5).numpy() # -1 ~ 1 normalization \n",
    "    channel_cnt = img.shape[0]\n",
    "    if channel_cnt == 3 :\n",
    "        img = np.transpose(a=img, axes=(1, 2, 0))\n",
    "        plt.imshow(X=img) \n",
    "    elif channel_cnt == 1 : \n",
    "        img = np.squeeze(a=img, axis=0)\n",
    "        plt.imshow(X=img, cmap='gray')\n",
    "    else : \n",
    "        pass \n",
    "    plt.xlabel(xlabel=f'Target : {target}({df.classes[target]})')\n",
    "    plt.show()\n",
    "\n",
    "#(2) Define "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 00.3. **클래스 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Create `Generator` class\n",
    "class Generator(torch.nn.Module) :\n",
    "    def __init__(self, input_shape:list, latent_dim:int, device:torch.device) :\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.output_dim = input_shape[1] * input_shape[2]\n",
    "        self.device = device\n",
    "        self.linear_block = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=self.latent_dim, out_features=256),\n",
    "            torch.nn.LeakyReLU(negative_slope=0.2),\n",
    "            torch.nn.Linear(in_features=256, out_features=512),\n",
    "            torch.nn.LeakyReLU(negative_slope=0.2),\n",
    "            torch.nn.Linear(in_features=512, out_features=1024),\n",
    "            torch.nn.LeakyReLU(negative_slope=0.2),\n",
    "            torch.nn.Linear(in_features=1024, out_features=self.output_dim),\n",
    "            torch.nn.Tanh()\n",
    "        )\n",
    "        self.to(device=device)\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor :\n",
    "        x = x.to(device=self.device)\n",
    "        x = self.linear_block(x)\n",
    "        x = x.reshape(shape=(-1, 1, 28, 28))\n",
    "        return x\n",
    "\n",
    "#(2) Create `Discriminator` class\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, input_shape:list, device:torch.device) :\n",
    "        super().__init__()\n",
    "        self.input_dim = input_shape[1] * input_shape[2]\n",
    "        self.device = device\n",
    "        self.linear_block = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=self.input_dim, out_features=1024),\n",
    "            torch.nn.LeakyReLU(negative_slope=0.2),\n",
    "            torch.nn.Dropout(p=0.3),\n",
    "            torch.nn.Linear(in_features=1024, out_features=512),\n",
    "            torch.nn.LeakyReLU(negative_slope=0.2),\n",
    "            torch.nn.Dropout(p=0.3),\n",
    "            torch.nn.Linear(in_features=512, out_features=256),\n",
    "            torch.nn.LeakyReLU(negative_slope=0.2),\n",
    "            torch.nn.Dropout(p=0.3),\n",
    "            torch.nn.Linear(in_features=256, out_features=1), \n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        self.to(device=device)\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor :\n",
    "        x = x.to(device=self.device)\n",
    "        x = x.reshape(shape=(-1, 784))\n",
    "        x = self.linear_block(x)\n",
    "        return x \n",
    "    \n",
    "#(3) Define `TrainLogger` class\n",
    "class TrainLogger : \n",
    "    def __init__(self) :\n",
    "        self.train_log = {\n",
    "            'epoch'       : [],\n",
    "            'inputs_real' : [],\n",
    "            'preds_real'  : [],\n",
    "            'preds_fake'  : []\n",
    "        }\n",
    "    def log(self, epoch:int, inputs:torch.Tensor, preds:torch.Tensor, path:str) :\n",
    "        self.train_log['epoch'].append(epoch)\n",
    "        self.train_log['inputs_real'].append(inputs)\n",
    "        self.train_log['preds_real'].append(preds)\n",
    "        self.train_log['preds_fake'].append(preds)\n",
    "        torch.save(obj={'train_log':self.train_log}, f=path)\n",
    "    def move_device(self, device:str) :\n",
    "        for i in range(len(self.train_log['inputs'])) :\n",
    "            if (device == 'cpu') :\n",
    "                self.train_log['inputs_real'][i] = self.train_log['inputs_real'][i].detach().cpu().numpy()\n",
    "                self.train_log['preds_real'][i] = self.train_log['preds_real'][i].detach().cpu().numpy()\n",
    "                self.train_log['preds_fake'][i] = self.train_log['preds_fake'][i].detach().cpu().numpy()\n",
    "            else :\n",
    "                self.train_log['inputs_real'][i] = self.train_log['inputs_real'][i].to(device=device)\n",
    "                self.train_log['preds_real'][i] = self.train_log['preds_real'][i].to(device=device)\n",
    "                self.train_log['preds_fake'][i] = self.train_log['preds_fake'][i].to(device=device)\n",
    "\n",
    "#(4) Define `Visualizer` class\n",
    "class Visualizer :    \n",
    "    def __init__(self, train_log:dict, fig_size:tuple=(8, 8)) :\n",
    "        self.train_log = train_log\n",
    "        self.fig_size = fig_size\n",
    "        self.epoch_min = min(self.train_log['epoch'])\n",
    "        self.epoch_max = max(self.train_log['epoch'])\n",
    "        self.epoch_num = len(train_log['epoch']) - 1\n",
    "        self.sample_num = train_log['inputs_real'][0].shape[0] - 1\n",
    "        self.widget_output = ipywidgets.Output(\n",
    "            layout=ipywidgets.Layout(\n",
    "                width='auto', \n",
    "                height='auto', \n",
    "                margin='0px', \n",
    "                padding='0px'\n",
    "            )\n",
    "        )\n",
    "        self.epoch_play = ipywidgets.Play(\n",
    "            min=self.epoch_min,\n",
    "            max=self.epoch_max,\n",
    "            step=1,\n",
    "            value=0,\n",
    "            interval=250,\n",
    "            description='Epoch Play',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.epoch_play.add_class(className='white-play')\n",
    "        self.epoch_slider = ipywidgets.IntSlider(\n",
    "            min=self.epoch_min,\n",
    "            max=self.epoch_max,\n",
    "            step=1,\n",
    "            value=0,\n",
    "            description='Epoch',\n",
    "            continuous_update=True,\n",
    "            orientation='horizontal',\n",
    "            readout=True,\n",
    "            readout_format='d'\n",
    "        )\n",
    "        self.sample_slider = ipywidgets.IntSlider(\n",
    "            min=0,\n",
    "            max=self.sample_num,\n",
    "            step=1,\n",
    "            value=0,\n",
    "            description='Sample',\n",
    "            continuous_update=True,\n",
    "            orientation='horizontal',\n",
    "            readout=True,\n",
    "            readout_format='d'\n",
    "        )\n",
    "        ipywidgets.jslink(attr1=(self.epoch_play, 'value'), attr2=(self.epoch_slider, 'value'))\n",
    "        self.epoch_slider.observe(handler=self.on_epoch_change, names='value')\n",
    "        self.sample_slider.observe(handler=self.on_sample_change, names='value')\n",
    "        with self.widget_output:\n",
    "            self.fig, (self.ax1, self.ax2, self.ax3) = plt.subplots(nrows=1, ncols=3, figsize=self.fig_size)\n",
    "            try:\n",
    "                self.fig.canvas.header_visible = False\n",
    "                self.fig.canvas.toolbar_visible = False\n",
    "            except:\n",
    "                pass\n",
    "            plt.show()\n",
    "        self.update_view()\n",
    "    def on_epoch_change(self, change:dict) :\n",
    "        self.update_view()\n",
    "    def on_sample_change(self, change:dict) :\n",
    "        self.update_view()\n",
    "    def update_view(self) :\n",
    "        with self.widget_output:\n",
    "            self.ax1.clear()\n",
    "            self.ax2.clear()\n",
    "            ep_value = self.epoch_slider.value\n",
    "            ep_idx = self.train_log['epoch'].index(ep_value)\n",
    "            sp_idx = self.sample_slider.value\n",
    "            input_real_img = self.train_log['inputs_real'][ep_idx][sp_idx].squeeze()\n",
    "            pred_real_img = self.train_log['preds_real'][ep_idx][sp_idx].squeeze()\n",
    "            pred_fake_img = self.train_log['preds_fake'][ep_idx][sp_idx].squeeze()\n",
    "            self.ax1.imshow(X=input_real_img, cmap='gray')\n",
    "            self.ax1.set_title(label='Target', fontdict={'fontsize': 12})\n",
    "            self.ax1.set_aspect(aspect='auto')\n",
    "            self.ax1.axis('off')\n",
    "            self.ax2.imshow(X=pred_real_img, cmap='gray')\n",
    "            self.ax2.set_title(label='Prediction (Real)', fontdict={'fontsize': 12})\n",
    "            self.ax2.set_aspect(aspect='auto')\n",
    "            self.ax2.axis('off')\n",
    "            self.ax3.imshow(X=pred_fake_img, cmap='gray')\n",
    "            self.ax3.set_title(label='Prediction (Fake)', fontdict={'fontsize': 12})\n",
    "            self.ax3.set_aspect(aspect='auto')\n",
    "            self.ax3.axis('off')\n",
    "            self.fig.canvas.draw_idle()\n",
    "    def plot_compare(self) -> ipywidgets.widgets :\n",
    "        controls_box = ipywidgets.VBox(\n",
    "            children=[\n",
    "                self.epoch_slider,\n",
    "                self.sample_slider,\n",
    "                self.epoch_play\n",
    "            ],\n",
    "            layout=ipywidgets.Layout(\n",
    "                align_items='center',\n",
    "                margin='0% 0% 15% -5%'\n",
    "            )\n",
    "        )\n",
    "        ui = ipywidgets.HBox(\n",
    "            children=[self.widget_output, controls_box],\n",
    "            layout=ipywidgets.Layout(\n",
    "                justify_content='flex-start',\n",
    "                align_items='center',\n",
    "                width='auto',\n",
    "                margin='0px',\n",
    "                padding='0px'\n",
    "            )\n",
    "        )\n",
    "        display(ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. **데이터셋 전처리 및 로드**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 01.1. **이미지 전처리 파이프라인 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tf = torchvision.transforms.Compose(\n",
    "    transforms=[\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 01.2. **데이터셋 로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = torchvision.datasets.FashionMNIST(root='../../data', train=True, download=True, transform=img_tf)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root='../../data', train=False, download=True, transform=img_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 01.3. **EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(1) Print sample of train\n",
    "len(mnist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#(2) Display image\n",
    "show_img(df=mnist_train, index=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 28, 28]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(3) Check `input_size`\n",
    "input_shape = list(mnist_train[0][0].shape)\n",
    "\n",
    "#(4) Print `input_size`\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  count\n",
       "1      0   6000\n",
       "6      1   6000\n",
       "3      2   6000\n",
       "2      3   6000\n",
       "8      4   6000\n",
       "5      5   6000\n",
       "7      6   6000\n",
       "4      7   6000\n",
       "9      8   6000\n",
       "0      9   6000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(5) Print frequency of target class\n",
    "target_freq = collections.Counter()\n",
    "for i in range(len(mnist_train)):\n",
    "    input, target = mnist_train[i]\n",
    "    if isinstance(target, torch.Tensor) :\n",
    "        target = target.item()\n",
    "    target_freq[target] += 1\n",
    "pd.DataFrame(data=list(target_freq.items()), columns=['class', 'count']).sort_values(by='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 01.4. **데이터로더 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_loader = torch.utils.data.DataLoader(dataset=mnist_train, batch_size=BATCH_SIZE, shuffle=False)\n",
    "mnist_test_loader = torch.utils.data.DataLoader(dataset=mnist_test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. **모델 구축 및 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02.1. **하이퍼 파라미터 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02.2.1. **Generator 모델 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Generator                                [2, 1, 28, 28]            --\n",
       "├─Sequential: 1-1                        [2, 784]                  --\n",
       "│    └─Linear: 2-1                       [2, 256]                  33,024\n",
       "│    └─LeakyReLU: 2-2                    [2, 256]                  --\n",
       "│    └─Linear: 2-3                       [2, 512]                  131,584\n",
       "│    └─LeakyReLU: 2-4                    [2, 512]                  --\n",
       "│    └─Linear: 2-5                       [2, 1024]                 525,312\n",
       "│    └─LeakyReLU: 2-6                    [2, 1024]                 --\n",
       "│    └─Linear: 2-7                       [2, 784]                  803,600\n",
       "│    └─Tanh: 2-8                         [2, 784]                  --\n",
       "==========================================================================================\n",
       "Total params: 1,493,520\n",
       "Trainable params: 1,493,520\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 2.99\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.04\n",
       "Params size (MB): 5.97\n",
       "Estimated Total Size (MB): 6.02\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(1) Define `gen_model`\n",
    "gen_model = Generator(input_shape=input_shape, latent_dim=latent_dim, device=device)\n",
    "\n",
    "#(2) Display `gen_model`\n",
    "torchinfo.summary(\n",
    "    model=gen_model, \n",
    "    input_size=[BATCH_SIZE]+[latent_dim],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(4) Define optimizer(optimization method)\n",
    "gen_optimizer = torch.optim.Adam(params=gen_model.parameters(), lr=1e-3, weight_decay=1e-7)\n",
    "\n",
    "#(5) Define loss function\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "#(6) Define Scheduler\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "#(7) Define logger\n",
    "logger = TrainLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02.2.2. **Discriminator 모델 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Discriminator                            [2, 1]                    --\n",
       "├─Sequential: 1-1                        [2, 1]                    --\n",
       "│    └─Linear: 2-1                       [2, 1024]                 803,840\n",
       "│    └─LeakyReLU: 2-2                    [2, 1024]                 --\n",
       "│    └─Dropout: 2-3                      [2, 1024]                 --\n",
       "│    └─Linear: 2-4                       [2, 512]                  524,800\n",
       "│    └─LeakyReLU: 2-5                    [2, 512]                  --\n",
       "│    └─Dropout: 2-6                      [2, 512]                  --\n",
       "│    └─Linear: 2-7                       [2, 256]                  131,328\n",
       "│    └─LeakyReLU: 2-8                    [2, 256]                  --\n",
       "│    └─Dropout: 2-9                      [2, 256]                  --\n",
       "│    └─Linear: 2-10                      [2, 1]                    257\n",
       "│    └─Sigmoid: 2-11                     [2, 1]                    --\n",
       "==========================================================================================\n",
       "Total params: 1,460,225\n",
       "Trainable params: 1,460,225\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 2.92\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.03\n",
       "Params size (MB): 5.84\n",
       "Estimated Total Size (MB): 5.88\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(1) Define `disc_model`\n",
    "disc_model = Discriminator(input_shape=input_shape, device=device)\n",
    "\n",
    "#(2) Display `disc_model`\n",
    "torchinfo.summary(\n",
    "    model=disc_model, \n",
    "    input_size=[BATCH_SIZE]+input_shape,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3) Define optimizer(optimization method)\n",
    "disc_optimizer = torch.optim.Adam(params=disc_model.parameters(), lr=1e-3, weight_decay=1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02.2. **학습 전 변수 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch=0, Best Total Train Loss=inf, Train Loss={'total_loss': [], 'gen_loss': [], 'disc_real_loss': [], 'disc_fake_loss': []}\n"
     ]
    }
   ],
   "source": [
    "epoch = 0 \n",
    "loss_hist = {\n",
    "    'total_loss'     : [],\n",
    "    'gen_loss'       : [],\n",
    "    'disc_real_loss' : [],\n",
    "    'disc_fake_loss' : []\n",
    "}\n",
    "best_loss = {\n",
    "    'total_loss'     : 0.0,\n",
    "    'gen_loss'       : 0.0,        \n",
    "    'disc_real_loss' : 0.0,\n",
    "    'disc_fake_loss' : 0.0\n",
    "}\n",
    "best_total_loss = float('inf')\n",
    "if USE_CHECKPOINT_YN == 'Y' :\n",
    "    try :\n",
    "        checkpoint = torch.load(f=MODEL_PTH, map_location=device)\n",
    "        gen_model.load_state_dict(state_dict=checkpoint['gen_model'])\n",
    "        gen_optimizer.load_state_dict(state_dict=checkpoint['gen_optimizer'])\n",
    "        disc_model.load_state_dict(state_dict=checkpoint['disc_model'])\n",
    "        disc_optimizer.load_state_dict(state_dict=checkpoint['disc_optimizer'])\n",
    "        epoch = checkpoint['best_epoch']\n",
    "        loss_hist = checkpoint['loss_hist']\n",
    "        # best_loss = loss_hist[-1]\n",
    "        best_total_loss = loss_hist['gen_loss'][-1] + loss_hist['disc_real_loss'][-1] + loss_hist['disc_fake_loss'][-1]\n",
    "        # logger.train_log = torch.load(f=LOGGER_PTH, map_location=device)['train_log']\n",
    "    except Exception :\n",
    "        pass\n",
    "print(f'>> Epoch={epoch}, Best Total Train Loss={best_total_loss}, Train Loss={loss_hist}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02.3. **모델 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "batch_len = len(mnist_train_loader)\n",
    "best_epoch = epoch\n",
    "progress_bar = tqdm.trange(epoch+1, EPOCH_NUM+1)\n",
    "for epoch in progress_bar : \n",
    "    last_loss = {\n",
    "        'total_loss'     : 0.0,\n",
    "        'gen_loss'       : 0.0,        \n",
    "        'disc_real_loss' : 0.0,\n",
    "        'disc_fake_loss' : 0.0\n",
    "    }\n",
    "    gen_model.train()\n",
    "    disc_model.train()\n",
    "    for batch_idx, (inputs_real, targets) in enumerate(iterable=mnist_train_loader) :\n",
    "        disc_model.requires_grad_(requires_grad=True)\n",
    "        disc_optimizer.zero_grad()\n",
    "        current_batch_size = inputs_real.shape[0]\n",
    "        # ---- ---- #\n",
    "        labels_real = torch.ones(size=(current_batch_size, 1), device=device)\n",
    "        preds_real = disc_model(x=inputs_real)\n",
    "        disc_real_loss = criterion(input=preds_real, target=labels_real)\n",
    "        # ---- ---- #\n",
    "        noise = torch.randn(size=(current_batch_size, latent_dim), device=device)\n",
    "        inputs_fake = gen_model(x=noise)\n",
    "        labels_fake = torch.zeros(size=(current_batch_size, 1), device=device)\n",
    "        preds_fake = disc_model(x=inputs_fake)\n",
    "        disc_fake_loss = criterion(input=preds_fake, target=labels_fake)\n",
    "        # ---- ---- #\n",
    "        disc_total_loss = disc_real_loss + disc_fake_loss\n",
    "        disc_total_loss.backward()\n",
    "        disc_optimizer.step()\n",
    "        # ---- ---- #\n",
    "        last_loss['disc_real_loss'] += disc_real_loss.item()\n",
    "        last_loss['disc_fake_loss'] += disc_fake_loss.item()\n",
    "        # ---- ---- #\n",
    "        disc_model.requires_grad_(requires_grad=False)\n",
    "        gen_optimizer.zero_grad() \n",
    "        noise = torch.randn(size=(current_batch_size, latent_dim), device=device)\n",
    "        inputs_fake = gen_model(x=noise)\n",
    "        preds_fake = disc_model(x=inputs_fake)\n",
    "        gen_loss = criterion(input=preds_fake, target=labels_real)\n",
    "        gen_loss.backward()\n",
    "        gen_optimizer.step()\n",
    "        last_loss['gen_loss'] += gen_loss.item()\n",
    "        # ---- ---- #\n",
    "        if batch_idx == 0 : \n",
    "            inputs_real_b_0 = inputs_real\n",
    "            # inputs_fake_b_0 = inputs_fake\n",
    "            preds_real_b_0 = preds_real\n",
    "            preds_fake_b_0 = preds_fake\n",
    "    # logger.log(\n",
    "    #     epoch=epoch, \n",
    "    #     inputs_real=inputs_real_b_0, \n",
    "    #     preds_real=preds_real_b_0, \n",
    "    #     preds_fake=preds_fake_b_0, \n",
    "    #     path=LOGGER_PTH\n",
    "    # )\n",
    "    last_loss_avg = {\n",
    "        'total_loss_avg'     : (last_loss['gen_loss']+last_loss['disc_real_loss']+last_loss['disc_fake_loss']) / batch_len,\n",
    "        'gen_loss_avg'       : last_loss['gen_loss'] / batch_len, \n",
    "        'disc_real_loss_avg' : last_loss['disc_real_loss'] / batch_len,\n",
    "        'disc_fake_loss_avg' : last_loss['disc_fake_loss'] / batch_len,\n",
    "    }\n",
    "    loss_hist['total_loss'].append(last_loss_avg['total_loss_avg'])\n",
    "    loss_hist['gen_loss'].append(last_loss_avg['gen_loss_avg'])\n",
    "    loss_hist['disc_real_loss'].append(last_loss_avg['disc_real_loss_avg'])\n",
    "    loss_hist['disc_fake_loss'].append(last_loss_avg['disc_fake_loss_avg'])\n",
    "    last_total_loss = last_loss['gen_loss'] + last_loss['disc_real_loss'] + last_loss['disc_fake_loss']\n",
    "    if last_total_loss < best_total_loss :\n",
    "        best_epoch = epoch\n",
    "        best_total_loss = last_total_loss\n",
    "        torch.save(\n",
    "            obj={\n",
    "                'gen_model'      : gen_model.state_dict(),\n",
    "                'gen_optimizer'  : gen_optimizer.state_dict(),\n",
    "                'disc_model'     : disc_model.state_dict(),\n",
    "                'disc_optimizer' : disc_optimizer.state_dict(),\n",
    "                'best_epoch'     : best_epoch,\n",
    "                'loss_hist'      : loss_hist\n",
    "            }, \n",
    "            f=MODEL_PTH\n",
    "        )\n",
    "    # scheduler.step()\n",
    "    progress_bar.set_postfix(ordered_dict={'last_epoch':epoch, 'last_total_loss':last_total_loss, 'best_epoch':best_epoch, 'best_total_loss':best_total_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. **모델 평가**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03.1. **최적 성능 모델 로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f=MODEL_PTH, map_location=device)\n",
    "# model.load_state_dict(state_dict=checkpoint['model'])\n",
    "loss_total_hist = (loss_hist['disc_total_loss'] + loss_hist['gen_loss'])\n",
    "print(f'>> Best Epoch : {np.argmin(a=checkpoint[\"loss_hist\"])+1}, Best Loss : {np.min(a=checkpoint[\"loss_hist\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04.2. **과소 적합 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.xlabel(xlabel='epoch')\n",
    "plt.ylabel(ylabel='loss')\n",
    "plt.plot(loss_total_hist, label='Training Loss')\n",
    "plt.axvline(x=np.argmin(a=loss_total_hist), color='grey', linestyle='--', linewidth=0.6, label=f'Best Training Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03.3. **(에포크 별) 학습 과정 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(0) Set up interactive mode\n",
    "%matplotlib widget\n",
    "\n",
    "#(1) Move device\n",
    "logger.move_device(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2) Define `visualizer`\n",
    "viz = Visualizer(train_log=logger.train_log, fig_size=(8, 4))\n",
    "\n",
    "#(3) Set up interactive mode\n",
    "viz.plot_compare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03.4. **일반화 성능 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
