{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH05.1. **Variational Auto Encoder(VAE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. **작업 환경 설정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 00.0. **사전 변수 설정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_NUM = 2025\n",
    "BATCH_SIZE = 512\n",
    "EPOCH_NUM = 500\n",
    "USE_CHECKPOINT_YN = 'Y'\n",
    "MODEL_PTH = '../../model/AutoEncoder.pt'\n",
    "LOGGER_PTH = '../../log/AutoEncoderTrainLogger.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 00.1. **라이브러리 호출 및 옵션 설정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Device : mps\n"
     ]
    }
   ],
   "source": [
    "#(1) Import libraries\n",
    "import os\n",
    "import ipywidgets\n",
    "import random\n",
    "import tqdm\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torchvision\n",
    "import torchinfo\n",
    "\n",
    "#(2) Set up options\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED_NUM)\n",
    "random.seed(a=SEED_NUM)\n",
    "np.random.seed(seed=SEED_NUM)\n",
    "torch.use_deterministic_algorithms(mode=True)\n",
    "torch.manual_seed(seed=SEED_NUM)\n",
    "torch.mps.manual_seed(seed=SEED_NUM)\n",
    "\n",
    "#(3) Set up device\n",
    "if torch.backends.mps.is_available() :\n",
    "    device = torch.device(device='mps')\n",
    "else :\n",
    "    device = torch.device(device='cpu')\n",
    "print(f'>> Device : {device}')\n",
    "\n",
    "#(4) Set up HTML tag\n",
    "# display(ipywidgets.HTML(data=\n",
    "# '''\n",
    "# <style> \n",
    "#     .white-play button {\n",
    "#         background-color: white !important; \n",
    "#         color: black !important;\n",
    "#     } \n",
    "# </style>\n",
    "# '''\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 00.2. **사용자정의함수 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(df:torchvision.datasets, index:int) -> plt.figure :\n",
    "    img = df[index][0]\n",
    "    target = df[index][1]\n",
    "    img = (img/2+0.5).numpy() # -1 ~ 1 normalization \n",
    "    channel_cnt = img.shape[0]\n",
    "    if channel_cnt == 3 :\n",
    "        img = np.transpose(a=img, axes=(1, 2, 0))\n",
    "        plt.imshow(X=img) \n",
    "    elif channel_cnt == 1 : \n",
    "        img = np.squeeze(a=img, axis=0)\n",
    "        plt.imshow(X=img, cmap='gray')\n",
    "    else : \n",
    "        pass \n",
    "    plt.xlabel(xlabel=f'Target : {target}({df.classes[target]})')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 00.3. **클래스 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Define `Flatten` class\n",
    "class Flatten(torch.nn.Module) :\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor :\n",
    "        '''\n",
    "            (batch size, channel size , (image) height, image width) -> (batch size, channel size * image width * image height) \n",
    "                                                                     -> (batch size, channel size * (image size)**2) \n",
    "        '''\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.reshape(shape=(batch_size, -1))\n",
    "        return x \n",
    "\n",
    "#(2) Define `Unflatten` class\n",
    "class Unflatten(torch.nn.Module) :\n",
    "    def __init__(self, channel_num:int) :\n",
    "        super().__init__()\n",
    "        self.channel_num = channel_num\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor :\n",
    "        ''' \n",
    "            (batch size, channel size * (image) height * width) -> (batch size, channel size, height, width) \n",
    "        '''\n",
    "        shape = x.shape\n",
    "        img_size = int((shape[1]//self.channel_num)**0.5) \n",
    "        x = x.reshape(shape=(shape[0], self.channel_num, img_size, img_size))\n",
    "        return  x \n",
    "    \n",
    "#(3) Define `MyConvAutoEncoder` class\n",
    "class MyConvAutoEncoder(torch.nn.Module) :\n",
    "    def __init__(self, input_shape:list, channel_num:int, class_num:int, device:torch.device) :\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.channel_num = channel_num\n",
    "        self.device = device\n",
    "        flattened_size = self._compute_flatten_size()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=channel_num, kernel_size=3, stride=2), \n",
    "            torch.nn.ReLU(), \n",
    "            torch.nn.Conv2d(in_channels=channel_num, out_channels=2*channel_num, kernel_size=3, stride=2),\n",
    "            torch.nn.ReLU(), \n",
    "            torch.nn.Conv2d(in_channels=2*channel_num, out_channels=4*channel_num, kernel_size=3, stride=1),\n",
    "            torch.nn.ReLU(),\n",
    "            Flatten(),\n",
    "            torch.nn.Linear(in_features=flattened_size, out_features=class_num), \n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            Unflatten(channel_num=4*channel_num),\n",
    "            torch.nn.ConvTranspose2d(in_channels=4*channel_num, out_channels=2*channel_num, kernel_size=3, stride=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(in_channels=2*channel_num, out_channels=channel_num, kernel_size=3, stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(in_channels=channel_num, out_channels=1, kernel_size=3, stride=2, output_padding=1)\n",
    "        )\n",
    "        self.to(device=device)\n",
    "    def _compute_flatten_size(self) -> int :\n",
    "        with torch.no_grad() :\n",
    "            dummy_data = torch.zeros(size=(1, 1, self.input_shape[1], self.input_shape[2])).to(device=self.device)\n",
    "            dummy_fn = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels=1, out_channels=self.channel_num, kernel_size=3, stride=2), \n",
    "                torch.nn.ReLU(), \n",
    "                torch.nn.Conv2d(in_channels=self.channel_num, out_channels=2*self.channel_num, kernel_size=3, stride=2),\n",
    "                torch.nn.ReLU(), \n",
    "                torch.nn.Conv2d(in_channels=2*self.channel_num, out_channels=4*self.channel_num, kernel_size=3, stride=1),\n",
    "                torch.nn.ReLU()\n",
    "            ).to(device=device)\n",
    "            output = dummy_fn(dummy_data)\n",
    "        output = output.reshape(shape=(1, -1)).shape[1]\n",
    "        return output\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor :\n",
    "        x = x.to(device=device)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "#(3) Define `TrainLogger` class\n",
    "class TrainLogger : \n",
    "    def __init__(self) :\n",
    "        self.train_log = {\n",
    "            'epoch'  : [],\n",
    "            'inputs' : [],\n",
    "            'preds'  : []\n",
    "        }\n",
    "    def log(self, epoch:int, inputs:torch.Tensor, preds:torch.Tensor, path:str) :\n",
    "        self.train_log['epoch'].append(epoch)\n",
    "        self.train_log['inputs'].append(inputs)\n",
    "        self.train_log['preds'].append(preds)\n",
    "        torch.save(obj={'train_log':self.train_log}, f=path)\n",
    "    def move_device(self, device:str) :\n",
    "        for i in range(len(self.train_log['inputs'])) :\n",
    "            if (device == 'cpu') :\n",
    "                self.train_log['inputs'][i] = self.train_log['inputs'][i].detach().cpu().numpy()\n",
    "                self.train_log['preds'][i] = self.train_log['preds'][i].detach().cpu().numpy()\n",
    "            else :\n",
    "                self.train_log['inputs'][i] = self.train_log['inputs'][i].to(device=device)\n",
    "                self.train_log['preds'][i] = self.train_log['preds'][i].to(device=device)\n",
    "\n",
    "#(4) Define `Visualizer` class\n",
    "class Visualizer :    \n",
    "    def __init__(self, train_log:dict, fig_size:tuple=(8, 8)) :\n",
    "        self.train_log = train_log\n",
    "        self.fig_size = fig_size\n",
    "        self.epoch_min = min(self.train_log['epoch'])\n",
    "        self.epoch_max = max(self.train_log['epoch'])\n",
    "        self.epoch_num = len(train_log['epoch']) - 1\n",
    "        self.sample_num = train_log['inputs'][0].shape[0] - 1\n",
    "        self.widget_output = ipywidgets.Output(\n",
    "            layout=ipywidgets.Layout(\n",
    "                width='auto', \n",
    "                height='auto', \n",
    "                margin='0px', \n",
    "                padding='0px'\n",
    "            )\n",
    "        )\n",
    "        self.epoch_play = ipywidgets.Play(\n",
    "            min=self.epoch_min,\n",
    "            max=self.epoch_max,\n",
    "            step=1,\n",
    "            value=0,\n",
    "            interval=250,\n",
    "            description='Epoch Play',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.epoch_play.add_class(className='white-play')\n",
    "        self.epoch_slider = ipywidgets.IntSlider(\n",
    "            min=self.epoch_min,\n",
    "            max=self.epoch_max,\n",
    "            step=1,\n",
    "            value=0,\n",
    "            description='Epoch',\n",
    "            continuous_update=True,\n",
    "            orientation='horizontal',\n",
    "            readout=True,\n",
    "            readout_format='d'\n",
    "        )\n",
    "        self.sample_slider = ipywidgets.IntSlider(\n",
    "            min=0,\n",
    "            max=self.sample_num,\n",
    "            step=1,\n",
    "            value=0,\n",
    "            description='Sample',\n",
    "            continuous_update=True,\n",
    "            orientation='horizontal',\n",
    "            readout=True,\n",
    "            readout_format='d'\n",
    "        )\n",
    "        ipywidgets.jslink(attr1=(self.epoch_play, 'value'), attr2=(self.epoch_slider, 'value'))\n",
    "        self.epoch_slider.observe(handler=self.on_epoch_change, names='value')\n",
    "        self.sample_slider.observe(handler=self.on_sample_change, names='value')\n",
    "        with self.widget_output:\n",
    "            self.fig, (self.ax1, self.ax2) = plt.subplots(nrows=1, ncols=2, figsize=self.fig_size)\n",
    "            try:\n",
    "                self.fig.canvas.header_visible = False\n",
    "                self.fig.canvas.toolbar_visible = False\n",
    "            except:\n",
    "                pass\n",
    "            plt.show()\n",
    "        self.update_view()\n",
    "    def on_epoch_change(self, change:dict) :\n",
    "        self.update_view()\n",
    "    def on_sample_change(self, change:dict) :\n",
    "        self.update_view()\n",
    "    def update_view(self) :\n",
    "        with self.widget_output:\n",
    "            self.ax1.clear()\n",
    "            self.ax2.clear()\n",
    "            ep_value = self.epoch_slider.value\n",
    "            ep_idx = self.train_log['epoch'].index(ep_value)\n",
    "            sp_idx = self.sample_slider.value\n",
    "            input_img = self.train_log['inputs'][ep_idx][sp_idx].squeeze()\n",
    "            pred_img = self.train_log['preds'][ep_idx][sp_idx].squeeze()\n",
    "            self.ax1.imshow(X=input_img, cmap='gray')\n",
    "            self.ax1.set_title(label='Target', fontdict={'fontsize': 12})\n",
    "            self.ax1.set_aspect(aspect='auto')\n",
    "            self.ax1.axis('off')\n",
    "            self.ax2.imshow(X=pred_img, cmap='gray')\n",
    "            self.ax2.set_title(label='Prediction', fontdict={'fontsize': 12})\n",
    "            self.ax2.set_aspect(aspect='auto')\n",
    "            self.ax2.axis('off')\n",
    "            self.fig.canvas.draw_idle()\n",
    "    def plot_compare(self) -> ipywidgets.widgets :\n",
    "        controls_box = ipywidgets.VBox(\n",
    "            children=[\n",
    "                self.epoch_slider,\n",
    "                self.sample_slider,\n",
    "                self.epoch_play\n",
    "            ],\n",
    "            layout=ipywidgets.Layout(\n",
    "                align_items='center',\n",
    "                margin='0% 0% 15% -5%'\n",
    "            )\n",
    "        )\n",
    "        ui = ipywidgets.HBox(\n",
    "            children=[self.widget_output, controls_box],\n",
    "            layout=ipywidgets.Layout(\n",
    "                justify_content='flex-start',\n",
    "                align_items='center',\n",
    "                width='auto',\n",
    "                margin='0px',\n",
    "                padding='0px'\n",
    "            )\n",
    "        )\n",
    "        display(ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
